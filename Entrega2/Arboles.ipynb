{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BikBRpp8QfPc"
      },
      "source": [
        "# Proyecto 2. Entrega 2: Árboles de Decisión\n",
        "### Integrantes\n",
        "- Nelson García  \n",
        "- Diego Linares\n",
        "- Joaquin Puente\n",
        "- José Mérida\n",
        "- Joaquín Campos\n",
        "\n",
        "Las secciones de análisis exploratorio y separación del modelo se realizaron en la entrega anterior, sin embargo consideramos importante tener esta información a la mano para poder referenciarla dentro de este mismo documento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lywcs0mkQfPd"
      },
      "source": [
        "## Análisis exploratorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3Xzy1XVQfPd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeRegressor, plot_tree\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgpZsbJ5QfPe"
      },
      "source": [
        "### Carga de Datos y Revisión General"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "collapsed": true,
        "id": "OqWivY-yQfPe",
        "outputId": "7c329726-e038-4ba7-fc1d-d402d298fb01"
      },
      "outputs": [],
      "source": [
        "# estaremos definiendo ambos csvs para poder tener acceso a ambos pero usaremos el train y luego sobre el test replicaremos una vez se considere importante\n",
        "\n",
        "# Definir NA como nuestros NaN\n",
        "dftrain = pd.read_csv(\"train.csv\", na_values=[\"NA\"])\n",
        "\n",
        "# incluimos en el analissi exploratorio lo basico para poder tenerlo a la mano\n",
        "dftrain.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "collapsed": true,
        "id": "CWcjSK9SQfPe",
        "outputId": "52100b51-d8b1-4864-ca48-fd532ca786e0"
      },
      "outputs": [],
      "source": [
        "# datos estadísticos básicos\n",
        "dftrain.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "djGXh1trQfPe",
        "outputId": "314ecc9f-7a6c-4aac-8e67-e1b3e64a99fb"
      },
      "outputs": [],
      "source": [
        "# tipos\n",
        "dftrain.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ba6IV_SvQfPe",
        "outputId": "0d16ad45-11ac-4879-e72d-4fcbba75fc96"
      },
      "outputs": [],
      "source": [
        "# Revisamos posibles variables redundantes entre sí mismas\n",
        "print(dftrain.nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1sxWuX9TMpW"
      },
      "source": [
        "### Separación de Columnas por Tipo de Variable\n",
        "Algunas columnas cómo MSSubClass son categóricas nominales y cuentan con valores numéricos, además algunas otras columnas cómo pueden ser las de clasificación de estado son ordinales y tienen un encoding categórico (ej. Ex - Excelente en ExterCond). Es importante que clasifiquemos las diferentes variables para poder llevar a cabo el encoding de manera correcta y realizar nuestro análisis exploratorio. Tenemos 3 categorías:\n",
        "\n",
        "- Ordinales\n",
        "- Nominales\n",
        "- Numéricas\n",
        "\n",
        "Este proceso se lleva a cabo antes de depurar las columnas que no se utilizarán en el procesamiento de datos para evitar la necesidad de mantener en mente las columnas eliminadas al categorizar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr731YGrVSpk"
      },
      "outputs": [],
      "source": [
        "col_ordinales = ['OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n",
        "                 'BsmtExposure', 'HeatingQC',  'GarageQual', 'GarageCond', 'FireplaceQu',  'Functional',\n",
        "                 'KitchenQual', 'PoolQC', 'Fence']\n",
        "col_nominales = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
        "                 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
        "                 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
        "                 'Foundation', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'CentralAir', 'Electrical',\n",
        "                 'GarageFinish','GarageType','PavedDrive', 'MiscFeature', 'MoSold', 'SaleType', 'SaleCondition']\n",
        "col_numericas = ['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
        "                 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',\n",
        "                 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n",
        "                 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
        "                 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'YrSold']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJrwhI1KbLS9"
      },
      "source": [
        "Definimos una función para retornar el tipo de variable de cada columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtj7ldBGbODa"
      },
      "outputs": [],
      "source": [
        "def get_type(col):\n",
        "  if col in col_numericas + ['SalePrice']:\n",
        "    return 'numerica'\n",
        "  elif col in col_nominales:\n",
        "    return 'nominal'\n",
        "  elif col in col_ordinales:\n",
        "    return 'ordinal'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP1PeeMcbS2m"
      },
      "source": [
        "Verificamos que todas las columnas se hayan ingresado correctamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2UhbuWEbWyd",
        "outputId": "30fb32a1-7116-427d-8f47-48e7a7330a1a"
      },
      "outputs": [],
      "source": [
        "unassigned = []\n",
        "for col in dftrain.columns:\n",
        "  if get_type(col) == None:\n",
        "    unassigned.append(col)\n",
        "\n",
        "print(unassigned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i63e2o3sX_gI"
      },
      "source": [
        "### Datos Faltantes\n",
        "En este paso vamos a analizar datos faltantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVv6LFcOYXtB"
      },
      "source": [
        "Primero verificamos las columnas con valores nulos, para tener una mejor idea de que necesitamos hacer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSt88SqWYXB_",
        "outputId": "76d67802-aba8-42a4-8ba8-07d177a61544"
      },
      "outputs": [],
      "source": [
        "missing_values = dftrain.isnull().sum() / len(dftrain) * 100\n",
        "print(missing_values.sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCjro00GYiAA"
      },
      "source": [
        "Nos damos cuenta que PoolQC tiene 99.5% de valores faltantes, ¿Por qué?\n",
        "\n",
        "Algunas de las variables categóricas tienen cómo categoría \"NA\" y se toma como valor nulo al cargar los datos al DF. Creamos una lista con las variables que cuentan con esta característica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv3s3dRsYUPj"
      },
      "outputs": [],
      "source": [
        "na_as_data_cols = ['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
        "                   'FireplaceQu', 'GarageType', 'GarageFinish', 'PoolQC', 'Fence', 'MiscFeature',\n",
        "                   'MasVnrType', 'GarageQual', 'GarageCond']\n",
        "\n",
        "dftrain[na_as_data_cols] = dftrain[na_as_data_cols].fillna('Missing')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxq57qopemD5"
      },
      "source": [
        "Revisando nuevamente las columnas con valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IciuoKLfJD4",
        "outputId": "6052235e-cb4e-4341-f1aa-4bb4e82d666d"
      },
      "outputs": [],
      "source": [
        "missing_values = dftrain.isnull().sum() / len(dftrain) * 100\n",
        "print(missing_values.sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETbNNIAihoQt"
      },
      "source": [
        "Ahora tenemos valores faltantes más manejables, primero vamos a tomar LotFrontage y GarageYrBlt y reemplazar los valores faltantes con la mediana. Esto debido a que el 17.73% y 5.54% siguen siendo cifras bastante significativas y no podemos simplemente eliminar estas filas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuJQqHX-iNCY"
      },
      "outputs": [],
      "source": [
        "cols_to_fill = ['LotFrontage', 'GarageYrBlt']\n",
        "\n",
        "medians = dftrain[cols_to_fill].median()\n",
        "\n",
        "dftrain[cols_to_fill] = dftrain[cols_to_fill].fillna(medians)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK9IY_WejkSH"
      },
      "source": [
        "Revisando nuevamente los valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9u4VK1Ij4H-",
        "outputId": "b444ba60-a96d-480e-bc1d-e7762ff2cd03"
      },
      "outputs": [],
      "source": [
        "missing_values = dftrain.isnull().sum() / len(dftrain) * 100\n",
        "print(missing_values.sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQVLZ9fcj-4r"
      },
      "source": [
        "Ahora con una pequeña cantidad de valores faltantes, podemos simplemente remover las filas que los contengan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QSkIscZuj-lN",
        "outputId": "cf65ecfd-00a8-485f-c0b1-48c3793da398"
      },
      "outputs": [],
      "source": [
        "dftrain = dftrain.dropna()\n",
        "\n",
        "missing_values = dftrain.isnull().sum() / len(dftrain) * 100\n",
        "print(missing_values.sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85WmeFBxkcKa"
      },
      "source": [
        "Ya no tenemos valores faltantes dentro de nuestro DF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmNBGHFkP3NU"
      },
      "source": [
        "### Encoding de Variables Categóricas\n",
        "En este paso vamos a codificar las variables categóricas, las ordinales utilizando OrdinalEncoder y las nominales utilizando get_dummies. De esta manera podemos utilizar las variables ordinales cómo numéricas y aplicar las nominales a nuestro análisis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbvoQpErV-HQ"
      },
      "source": [
        "Identificamos los diferentes valores que puedan tomar las variables dentro del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XrMxwurjRp9j",
        "outputId": "35b924ee-63ae-4561-9487-979608266eab"
      },
      "outputs": [],
      "source": [
        "for col in col_ordinales:\n",
        "    print(f\"{col}: {dftrain[col].unique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsgNDXFKWoNJ"
      },
      "source": [
        "Aplicamos el encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vof0iiZsQp5O",
        "outputId": "1b39154b-2e72-40f2-8536-1a4cf71bb4c0"
      },
      "outputs": [],
      "source": [
        "# Diferentes categorías para las diferentes columnas\n",
        "standard_categories = ['Ex', 'Gd', 'TA', 'Fa', 'Po', 'Missing']\n",
        "fence_categories = ['GdPrv', 'MnPrv', 'GdWo', 'MnWw', 'Missing']\n",
        "bsmt_exposure_categories = ['No', 'Mn', 'Av', 'Gd', 'Missing']\n",
        "functional_categories = ['Typ', 'Min1', 'Min2', 'Mod', 'Maj1', 'Maj2', 'Sev', 'Missing']\n",
        "\n",
        "cleaned_ordinales = [x for x in col_ordinales if x not in ['OverallQual', 'OverallCond']]\n",
        "\n",
        "# Limpiamos los entries quitando posibles errores de espacios\n",
        "dftrain[cleaned_ordinales] = dftrain[cleaned_ordinales].astype(str).apply(lambda x: x.str.strip())\n",
        "\n",
        "# Asignación de categorías a columnas\n",
        "categories = []\n",
        "for col in cleaned_ordinales:\n",
        "    if col == 'Fence':\n",
        "        categories.append(fence_categories)\n",
        "    elif col == 'BsmtExposure':\n",
        "        categories.append(bsmt_exposure_categories)\n",
        "    elif col == 'Functional':\n",
        "        categories.append(functional_categories)\n",
        "    else:\n",
        "        categories.append(standard_categories)\n",
        "\n",
        "# Inicialización y aplicación de encoder\n",
        "encoder = OrdinalEncoder(categories=categories, handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "dftrain[cleaned_ordinales] = encoder.fit_transform(dftrain[cleaned_ordinales]).astype(int)\n",
        "\n",
        "# Verificacion de filas sin encodear\n",
        "print((dftrain[cleaned_ordinales] == -1).sum())\n",
        "\n",
        "# Conteo de valores por cada columna\n",
        "for col in cleaned_ordinales:\n",
        "    print(f\"{col}:\")\n",
        "    print(\"\\n\".join([f\"{val} - {count}\" for val, count in dftrain[col].value_counts().items()]))\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQEllw96lupr"
      },
      "source": [
        "Para las variables nominales, utilizamos get_dummies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5Ye1-5uylyhs",
        "outputId": "9eab3c4c-a7b1-48bc-d415-809cd0aeb66c"
      },
      "outputs": [],
      "source": [
        "dftrain = pd.get_dummies(dftrain, columns=col_nominales, prefix_sep='_')\n",
        "dftrain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8_-TRkQP67p"
      },
      "source": [
        "Con el output podemos observar que ya se encuentran codificadas nuestras variables categóricas ordinales utilizando valores numéricos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkKmaAAXVSLm"
      },
      "source": [
        "### Depuración de Datos\n",
        "En este paso revisamos si existen datos duplicados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYvtRp6ZQfPe"
      },
      "source": [
        "Eliminación de Filas Duplicadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI0-yg4XQfPe",
        "outputId": "8df1e66c-305e-439a-9a0c-c0a69ae799cb"
      },
      "outputs": [],
      "source": [
        "before = dftrain.shape[0]\n",
        "\n",
        "# Eliminar duplicados\n",
        "dftrain = dftrain.drop_duplicates()\n",
        "after = dftrain.shape[0]\n",
        "print(f\"Filas eliminadas: {before - after}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERnJBO1VQfPf"
      },
      "source": [
        "No existen filas duplicadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYSgtMwb8cnn"
      },
      "source": [
        "dftrain.drop('id', axis=2, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbvD7WzqQfPf"
      },
      "source": [
        "### Exploración Variable de Respuesta\n",
        "En este paso buscamos obtener más información sobre la variable respuesta, ya que nuestro interés es buscar predecirla."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGTLyvKyoy-G"
      },
      "source": [
        "¿Cómo se distribuye?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVCIKlWzoyaL",
        "outputId": "81256d37-1405-4657-b2ce-2f494b42572b"
      },
      "outputs": [],
      "source": [
        "sns.histplot(dftrain['SalePrice'], kde=True, color='skyblue', bins=30).set(title='Distribucion de SalePrice', xlabel='Precio de Venta', ylabel='Cantidad de Casas')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL14Xsh8qCWR"
      },
      "source": [
        "La variable SalePrice sigue una distribución cerca de la normal, con un sesgo hacia la derecha. Esto quiere decir que hay más casas con precios bajos a medios y pocas con precios muy altos. A parte del análisis gráfico, podemos obtener algunos datos adicionales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2ZVrsAtvqhkX",
        "outputId": "d6de62a2-87ec-47ec-fe94-48a272c9d80d"
      },
      "outputs": [],
      "source": [
        "print(dftrain['SalePrice'].describe())\n",
        "print(\"Skewness:\", dftrain['SalePrice'].skew())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMDMRaGvqpvR"
      },
      "source": [
        "¿Cuáles variables se correlacionan con la variable objetivo?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "r2Ov-gWTQfPf",
        "outputId": "66f55c62-16d2-41bf-993d-e14971952dab"
      },
      "outputs": [],
      "source": [
        "# cuántas categorías únicas hay por columna?\n",
        "print(dftrain.select_dtypes(include=['object']).nunique())\n",
        "\n",
        "print(\"Distribucion de categorias por columna: \")\n",
        "# Distribución de categorías por columna\n",
        "for col in dftrain.select_dtypes(include=['object']).columns:\n",
        "    print(dftrain[col].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pf1iqbeQfPf"
      },
      "source": [
        "Gracias a este output podemos \"observar\" de forma rápida, que algunas de las variables como utilities, un poco LandSlope, Condition2 y tal vez otras variables pueden ser eliminadas, pero necesitamos poder justificar, de esta forma igual ya nos podemos hacer una idea de como hay algunas variables que tienen poca relevancia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ9auPR0XRI5"
      },
      "source": [
        "### Exploración Variables Categóricas Ordinales\n",
        "En este paso buscamos obtener más información sobre las variables categóricas ordinales, buscando identificar cómo se distribuyen y que nos dicen sobre las casas del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VJgcD7I8lvJ_",
        "outputId": "9c14f4cf-de54-4ea0-89e3-58fb2c76a7ca"
      },
      "outputs": [],
      "source": [
        "# Generar gráficos para cada variable ordinal con respecto a SalePrice\n",
        "fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(18, 18))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(col_ordinales):\n",
        "    if col in dftrain.columns and dftrain[col].nunique() > 1:\n",
        "        sns.boxplot(data=dftrain, x=col, y=\"SalePrice\", ax=axes[i])\n",
        "        axes[i].set_title(f\"Distribución de SalePrice según {col}\")\n",
        "        axes[i].set_xlabel(col)\n",
        "        axes[i].set_ylabel(\"SalePrice\")\n",
        "    else:\n",
        "        axes[i].axis('off')  # Ocultar gráficos vacíos\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vDxwdFplvKA"
      },
      "source": [
        "Con base en la información que nos presentan los gráficos anteriores\n",
        "\n",
        "Podemos concluir que\n",
        "- La calidad general (OverallQual) es el factor ordinal más importante para determinar SalePrice.\n",
        "- Las características internas como KitchenQual y FireplaceQu tienen un fuerte impacto en el valor de la vivienda.\n",
        "- Condiciones estructurales (OverallCond, Functional) tienen menos influencia.\n",
        "- Elementos adicionales como piscinas pueden elevar significativamente el precio, pero su presencia es rara."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrEMDfkTrcb3"
      },
      "source": [
        "### Exploración Variables Categóricas Nominales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai4VJ5IAlvKB",
        "outputId": "e406ab3a-3941-4a01-86b4-eec3408daa98"
      },
      "outputs": [],
      "source": [
        "# Seleccionar solo las columnas codificadas\n",
        "encoded_cols = [col for col in dftrain.columns if any(col.startswith(nom) for nom in col_nominales)]\n",
        "\n",
        "# Calcular la correlación de las variables categóricas nominales con SalePrice\n",
        "correlations = dftrain[encoded_cols + ['SalePrice']].corr()['SalePrice'].sort_values(ascending=False)\n",
        "\n",
        "# Graficar las correlaciones más significativas\n",
        "correlations = correlations.dropna()\n",
        "correlations = correlations[correlations.abs() > 0.1]  # Filtrar solo las más relevantes\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=correlations.index, y=correlations.values, palette='coolwarm')\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel(\"Variables Categóricas Nominales Codificadas\")\n",
        "plt.ylabel(\"Correlación con SalePrice\")\n",
        "plt.title(\"Correlación entre Variables Categóricas Nominales y SalePrice\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STU8TtnylvKB"
      },
      "source": [
        "Con base en la gráfica anterior, podemos observar que\n",
        "\n",
        "- Ubicación (Neighborhood) es uno de los factores más determinantes en el precio de venta, se menciona por todos los campos que incluyen a (Neighborhood)\n",
        "- La calidad del cimiento (Foundation), el sótano (BsmtFinType1), el acabado del garaje (GarageFinish) y el tipo de vivienda también influyen significativamente.\n",
        "- Ciertas configuraciones como garajes separados o sistemas de calefacción deficientes pueden reducir el valor.\n",
        "- Algunas variables nominales, aunque intuitivamente importantes, tienen una baja correlación y pueden no ser determinantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNMRaFChQfPf"
      },
      "source": [
        "### Exploracion Variables Numéricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "-GwK1y-hQfPf",
        "outputId": "4f06844d-5a2c-445b-83b7-1e3f9bdb4865"
      },
      "outputs": [],
      "source": [
        "df_num = dftrain.select_dtypes(include = ['float64', 'int64'])\n",
        "df_num = df_num.drop('Id', axis=1)\n",
        "# Visualizacion y observacion variables numericas\n",
        "df_num.hist(figsize=(20, 18), bins=30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iqD5VmMQfPf"
      },
      "source": [
        "Gracias a esto podemos imaginar que hay bastantes variables con nulas, o como wooddeckSF en donde parece que la varianza es baja podemos identificar tambien que ademas hay bastantes varaibles que pueden sernos de gran utilidad en la busqueda de salesPrice pero sobre todo variables que tienden a una moda y como estas distribuciones que podriamos usar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "vmSe-s-KQfPf",
        "outputId": "373f1fb9-74cb-4bcc-a847-1551ebafebd8"
      },
      "outputs": [],
      "source": [
        "# Crear un solo gráfico con subplots\n",
        "num_cols = len(df_num.columns)\n",
        "ncols = 3\n",
        "nrows = (num_cols // ncols) + (num_cols % ncols > 0)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, nrows * 3))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(df_num.columns):\n",
        "    sns.boxplot(x=df_num[col], ax=axes[i])\n",
        "    axes[i].set_title(col)\n",
        "    axes[i].set_xlabel(\"\")\n",
        "\n",
        "# Ocultar gráficos vacíos si hay menos columnas que subplots\n",
        "total_axes = len(axes)\n",
        "for i in range(num_cols, total_axes):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ29JnMYQfPf"
      },
      "source": [
        "Segun esto podemos ver que la correlacion entre las variables númericas pero aún asi no podemos descartar ninguna variable porque la correlacion no tienen numeros altos para poder eliminarla con justificacion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJTGnPbHsPk2"
      },
      "source": [
        "## Separación del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCAt62YnlvKI"
      },
      "source": [
        "Gracias a ambos analisis, podemos determinar que la variable con mas relacion a SalePrice, es OverallQual, de esta forma para hacer la particion del subconjunto de prueba y entrenamiento, podemos ayudarnos de esta.\n",
        "\n",
        "Se usará la particion 80/20 de manera que el 80% del dataset(train.csv) se usará para entrenamiento, y el 20% del dataset(train.csv) se usara para prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XVfjzmSblvKJ",
        "outputId": "f4024e90-0df5-4111-bb4e-a81ddb899381"
      },
      "outputs": [],
      "source": [
        "train_set_strat, test_set_strat = train_test_split(\n",
        "    dftrain,\n",
        "    test_size=0.2,\n",
        "    stratify=dftrain[\"OverallQual\"],\n",
        "    random_state=42  #Asegura reproducibilidad\n",
        ")\n",
        "\n",
        "print(\"Tamaño de train:\", train_set_strat.shape[0])\n",
        "print(\"Tamaño de test:\", test_set_strat.shape[0])\n",
        "\n",
        "train_distribution = train_set_strat[\"OverallQual\"].value_counts(normalize=True).sort_index()\n",
        "test_distribution = test_set_strat[\"OverallQual\"].value_counts(normalize=True).sort_index()\n",
        "\n",
        "distribution_df = pd.DataFrame({\n",
        "    \"OverallQual\": train_distribution.index,\n",
        "    \"Train Proportion\": train_distribution,\n",
        "    \"Test Proportion\": test_distribution.reindex(train_distribution.index, fill_value=0)\n",
        "}).reset_index(drop=True)\n",
        "\n",
        "print(distribution_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77BWBRnj0-oC"
      },
      "source": [
        "## Árbol de Regresión (Sin Max Depth)\n",
        "En esta sección implementamos un árbol de regresión para predecir el precio de las casas utilizando todas las variables. Se utiliza para predecir el precio de las casas y se analiza el rendimiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LISzHx7CcYEc"
      },
      "source": [
        "### Entrenamiento del Arbol\n",
        "En esta sección separamos los splits X e Y de entrenamiento y prueba, utilizando el DecisionTreeRegressor de SKLearn para entrenar nuestro modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6HtJXGH-CVU"
      },
      "source": [
        "Separación de splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQl0H6no-IEW"
      },
      "outputs": [],
      "source": [
        "X_train = train_set_strat.drop(columns=['SalePrice'])\n",
        "Y_train = train_set_strat['SalePrice']\n",
        "\n",
        "X_test = test_set_strat.drop(columns=['SalePrice'])\n",
        "Y_test = test_set_strat['SalePrice']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "507JEeZu-eks"
      },
      "source": [
        "Entrenamiento del árbol de regresión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "RAbzkE28-iQe",
        "outputId": "73884d9c-f88f-49a2-db07-94c3c4796c45"
      },
      "outputs": [],
      "source": [
        "regressor = DecisionTreeRegressor(random_state = 42)\n",
        "\n",
        "regressor.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E_cnfo4ckcw"
      },
      "source": [
        "### Predicciones\n",
        "En esta sección aplicamos nuestra regresión a ambos conjuntos, el conjunto de prueba y el conjunto de entrenamiento. Esto con la finalidad de determinar el rendimiento de nuestro modelo y poder determinar si existe overfitting al utilizar todas las variables disponibles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_c5rGZy-qic"
      },
      "outputs": [],
      "source": [
        "Y_pred = regressor.predict(X_test)\n",
        "Y_train_pred = regressor.predict(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylVgLDCsdGDl"
      },
      "source": [
        "### Análisis\n",
        "En esta sección indagamos sobre los indicadores y gráficas necesarias para determinar y explicar el rendimiento de nuestro modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9UlHORogzdT"
      },
      "source": [
        "***Análisis MSE, MAE y R²***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsPWBJRqgtoV",
        "outputId": "8cb88187-6cb1-49b0-a6e7-994660e1b098"
      },
      "outputs": [],
      "source": [
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "mae = mean_absolute_error(Y_test, Y_pred)\n",
        "r2 = r2_score(Y_test, Y_pred)\n",
        "\n",
        "print(\"Test\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared (R²): {r2}\")\n",
        "\n",
        "mse = mean_squared_error(Y_train, Y_train_pred)\n",
        "mae = mean_absolute_error(Y_train, Y_train_pred)\n",
        "r2 = r2_score(Y_train, Y_train_pred)\n",
        "\n",
        "print(\"Train\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared (R²): {r2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXbW-kCHhCBn"
      },
      "source": [
        "**Rendimiento en Entrenamiento**\n",
        "- R²: 1.0\n",
        "- MSE: 0.0\n",
        "- MAE: 0.0\n",
        "\n",
        "**Rendimiento en Prueba**\n",
        "- R²: 0.71\n",
        "- MSE: 1906093576.18\n",
        "- MAE: 27635.80\n",
        "\n",
        "\n",
        "_R² de 1.0 en el set de entrenamiento, ¿El modelo perfecto?_\n",
        "\n",
        "No, el rendimiento en el entrenamiento sugiere un performance completamente perfecto. Esto lo que indica, es que el modelo se adaptó **demasiado** bien al conjunto de entrenamiento y se memorizó todo el ruido y los datos atípicos presentes dentro de este split. Lo que se busca dentro del modelo es que se encuentren patrones generalizables para poder predecir correctamente otros sets de datos.\n",
        "\n",
        "_Rendimiento de Prueba_\n",
        "\n",
        "Al analizar las estadísticas en el conjunto de prueba, nos damos cuenta que efectivamente si hay overfitting. La diferencia en rendimiento es bastante significativa, por lo que la adapción tan cercana al conjunto de entrenamiento prueba ser contraproducente.\n",
        "\n",
        "_Posibles Causas_\n",
        "\n",
        "Es bastante común que los árboles de regresión sufran de overfitting. Además, por default el DecisionTreeRegressor en scikit-learn no limita la profundidad del árbol. Eso aumenta el overfitting, ya que este árbol seguirá creciendo hasta que llegue a ajustarse completamente a los datos de entrenamiento.\n",
        "\n",
        "_Ajustes_\n",
        "\n",
        "Una manera que se pueden explorar ajustes en el modelo es modificar el parámetro de profundidad. Esto previene que el árbol siga creciendo indefinidamente sobre-ajustándose a los datos de prueba y busque predecir de manera perfecta cada dato atípico o particularidad de los datos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KYpFGQ_lcvx"
      },
      "source": [
        "***Información Sobre el Árbol***\n",
        "\n",
        "Debido a la profundidad del árbol, resulta sumamente complicado graficarlo y llegar a conclusiones basados en la gráfica. Debido a esto, decidimos obtener diferentes características del árbol y analizarlo de esa manera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PASf4JZlsVu",
        "outputId": "70263b6d-5ba5-4fb8-99de-fdd5e6e1a163"
      },
      "outputs": [],
      "source": [
        "print(f\"Profundidad: {regressor.tree_.max_depth}\")\n",
        "print(f\"Numero de Hojas: {regressor.get_n_leaves()}\")\n",
        "print(f\"Samples Promedio por Hoja: {np.mean(regressor.tree_.n_node_samples[np.where(regressor.tree_.children_left == regressor.tree_.children_right)[0]]):.2f}\")\n",
        "print(f\"Hoja con Más Samples: {np.max(regressor.tree_.n_node_samples[np.where(regressor.tree_.children_left == regressor.tree_.children_right)[0]])}\")\n",
        "print(f\"Cantidad de Datos de Entrenamiento:  {len(train_set_strat)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GppCF5kBnM50"
      },
      "source": [
        "Los datos obtenidos respaldan nuestro análisis anterior, explicando la existencia del over-fitting. ¿Por qué?\n",
        "\n",
        "*Profundidad: 26*\n",
        "\n",
        "Esto nos indica que hay 26 niveles diferentes dónde se separan los datos, lo cuál es una profundidad bastante alta para el árbol.\n",
        "\n",
        "*Número de Hojas: 1112*\n",
        "\n",
        "Estos son los nodos dónde \"terminan\" los datos para predecir su precio, teniendo 1160 datos y 1112 hojas indica que existe un nodo específico para cada uno de los datos casi todas las veces. Esto nos lleva a cumplir condiciones **sumamente específicas** para llegar a cada uno, adaptándose muy bien a los datos de entrenamiento pero talvez no a los de prueba.\n",
        "\n",
        "*Samples Promedio por Hoja: 1.04*\n",
        "\n",
        "Respaldando el análisis del inciso anterior, la cantidad de nodos por hoja es sumamente baja. Esto quiere decir que el árbol esta prediciendo específicamente cada uno de los datos, en vez de buscar patrones más generalizables que puedan categorizar datos nuevos.\n",
        "\n",
        "*Hoja con Más Samples: 3*\n",
        "\n",
        "El 'grupo' más grande dentro del grupo de entrenamiento del árbol fue de 3 samples, el modelo no logró reconocer alguna otra similaridad entre los datos\n",
        "\n",
        "*Conclusiones*\n",
        "\n",
        "La profundidad y la forma del árbol explica el overfitting descrito en el análisis de eficiencia del modelo. Además, apoya la sugerencia de variar el parámetro de profundidad para llegar a un modelo que tenga la capacidad de reconocer patrones generales y no específicos del set de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXkcRgjekBYg"
      },
      "source": [
        "***Gráficas***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv2afGqwp84V"
      },
      "source": [
        "**Valores Reales vs Predicciones**\n",
        "\n",
        "Buscamos analizar de manera gráfica los valores reales en comparación de los predecidos por el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "collapsed": true,
        "id": "4FXV5opZ_XCv",
        "outputId": "7c84f99f-adee-48dd-a794-dcc9924cd6ea"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(Y_test, Y_pred, alpha=0.5)\n",
        "plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', linestyle='--')  # Diagonal line\n",
        "plt.xlabel(\"Valores Reales\")\n",
        "plt.ylabel(\"Predicciones\")\n",
        "plt.title(\"Valores Reales vs Predicciones\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caLAXHZCp7mP"
      },
      "source": [
        "En la gráfica podemos observar lo siguiente:\n",
        "\n",
        "- Los puntos parecen estar distribuidos bastante uniformemente entre estar por encima y por abajo de la línea roja. Esto indica que no hay un over / under prediction significativo\n",
        "\n",
        "- Los valores pequeños se encuentran bastante cercanos a la línea, sin embargo mientras esta crece se van alejando más. Indicando que los errores crecen para valores más altos. Esto puede darse debido a la alta diferencia entre valores (100,000 vs 600,000) o errores dentro del modelo.\n",
        "\n",
        "- Existen algunos valores atípicos bastante alejados de los demás puntos, esto se puede dar debido a la inhabilidad del modelo de encontrar algunos patrones más complejos. O bien, debido al over-fitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "collapsed": true,
        "id": "x2Q6JSp5_tjy",
        "outputId": "7d44733b-e905-49e1-f4ee-68fed6773b2f"
      },
      "outputs": [],
      "source": [
        "residuals = Y_test - Y_pred\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(Y_pred, residuals, alpha=0.5)\n",
        "plt.axhline(y=0, color='red', linestyle='--')  # Horizontal line at 0\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual Plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQmmgeuHrxn5"
      },
      "source": [
        "La gráfica de residuos nos indica que la precisión del modelo decrece conforme el valor de la propiedad aumenta. Esta información se puede utilizar para variar los parámetros del árbol, o transformar variables de manera que se ajusten de mejor manera a la regresión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "ZkMcx4HiO4xa",
        "outputId": "fe1dfeec-3eb5-40ca-b3a3-761b9896499a"
      },
      "outputs": [],
      "source": [
        "# Get feature importances\n",
        "feature_importances = regressor.feature_importances_\n",
        "\n",
        "# Create a DataFrame to store feature names and their importances\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance (descending order)\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display the top 10 most important features\n",
        "print(\"Top 10 Most Important Features:\")\n",
        "print(importance_df.head(10))\n",
        "\n",
        "# Plot the feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(importance_df['Feature'][:10], importance_df['Importance'][:10], color='skyblue')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Top 10 Most Important Features')\n",
        "plt.gca().invert_yaxis()  # Invert y-axis to show the most important feature at the top\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cmn6eTw1Ctl"
      },
      "source": [
        "## Árbol de Regresión (Max Depth = 13)\n",
        "El objetivo principal de esta iteración es evitar el over-fitting, por lo que decidimos cortar la profundidad a la mitad. Esperamos ver un modelo que se adapte mejor a patrones generales, en vez de intentar agrupar cada uno de los datos de entrenamiento dentro de su misma categoría."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO-Yt4O50LY-"
      },
      "source": [
        "### Entrenamiento del Modelo y Predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqW4Q4Vo0T2s"
      },
      "outputs": [],
      "source": [
        "X_train = train_set_strat.drop(columns=['SalePrice'])\n",
        "Y_train = train_set_strat['SalePrice']\n",
        "\n",
        "X_test = test_set_strat.drop(columns=['SalePrice'])\n",
        "Y_test = test_set_strat['SalePrice']\n",
        "\n",
        "regressor = DecisionTreeRegressor(random_state = 42, max_depth = 13)\n",
        "\n",
        "regressor.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = regressor.predict(X_test)\n",
        "Y_train_pred = regressor.predict(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlnql6kE0_Ez"
      },
      "source": [
        "### Rendimiento del Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtiyL3V-08yp",
        "outputId": "38f3f74b-2f23-44eb-9bad-74728612f6fc"
      },
      "outputs": [],
      "source": [
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "mae = mean_absolute_error(Y_test, Y_pred)\n",
        "r2 = r2_score(Y_test, Y_pred)\n",
        "\n",
        "print(\"Test\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared (R²): {r2}\")\n",
        "\n",
        "mse = mean_squared_error(Y_train, Y_train_pred)\n",
        "mae = mean_absolute_error(Y_train, Y_train_pred)\n",
        "r2 = r2_score(Y_train, Y_train_pred)\n",
        "\n",
        "print(\"Train\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared (R²): {r2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLL4V2XcOMa_"
      },
      "source": [
        "### Gráficas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "PpEx5TDwON6C",
        "outputId": "77f83df0-fc5a-4b4b-b729-cbd092e87519"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(Y_test, Y_pred, alpha=0.5)\n",
        "plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', linestyle='--')  # Diagonal line\n",
        "plt.xlabel(\"Valores Reales\")\n",
        "plt.ylabel(\"Predicciones\")\n",
        "plt.title(\"Valores Reales vs Predicciones\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "swAu5zdlOQDY",
        "outputId": "c580b28d-4357-4a54-900f-54dc6417d799"
      },
      "outputs": [],
      "source": [
        "residuals = Y_test - Y_pred\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(Y_pred, residuals, alpha=0.5)\n",
        "plt.axhline(y=0, color='red', linestyle='--')  # Horizontal line at 0\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual Plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ifo35Xks1lR"
      },
      "source": [
        "## Árbol de Regresión (Max Depth = 4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YApYbcbd1Vgu"
      },
      "source": [
        "### Entrenamiento del Modelo y Predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVQbJep01YB5"
      },
      "outputs": [],
      "source": [
        "X_train = train_set_strat.drop(columns=['SalePrice'])\n",
        "Y_train = train_set_strat['SalePrice']\n",
        "\n",
        "X_test = test_set_strat.drop(columns=['SalePrice'])\n",
        "Y_test = test_set_strat['SalePrice']\n",
        "\n",
        "regressor = DecisionTreeRegressor(random_state = 42, max_depth =4)\n",
        "\n",
        "regressor.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = regressor.predict(X_test)\n",
        "Y_train_pred = regressor.predict(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAWOvwa23DEs"
      },
      "source": [
        "### Rendimiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9eBUIDB1aYJ",
        "outputId": "d90e48a4-e3c2-4b1d-f053-9f51ea89b8a2"
      },
      "outputs": [],
      "source": [
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "mae = mean_absolute_error(Y_test, Y_pred)\n",
        "r2 = r2_score(Y_test, Y_pred)\n",
        "\n",
        "print(\"Test\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared (R²): {r2}\")\n",
        "\n",
        "mse = mean_squared_error(Y_train, Y_train_pred)\n",
        "mae = mean_absolute_error(Y_train, Y_train_pred)\n",
        "r2 = r2_score(Y_train, Y_train_pred)\n",
        "\n",
        "print(\"Train\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared (R²): {r2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gráficas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(Y_test, Y_pred, alpha=0.5)\n",
        "plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', linestyle='--')  # Diagonal line\n",
        "plt.xlabel(\"Valores Reales\")\n",
        "plt.ylabel(\"Predicciones\")\n",
        "plt.title(\"Valores Reales vs Predicciones\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "residuals = Y_test - Y_pred\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(Y_pred, residuals, alpha=0.5)\n",
        "plt.axhline(y=0, color='red', linestyle='--')  # Horizontal line at 0\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual Plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM72qIPu3HN4"
      },
      "source": [
        "### Árbol de regresión (Max Depth = X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8BMSLMz67pV"
      },
      "source": [
        "## Fine-Tuning\n",
        "El objetivo en esta sección es diseñar un método similar al método del \"codo\" aplicado en clustering.\n",
        "\n",
        "*¿Por qué?*\n",
        "\n",
        "- Conforme aumenta el depth, la precisión del modelo en el conjunto de prueba empieza a llegar a un punto fijo.\n",
        "\n",
        "- Conforme aumenta el depth, aumenta el overfitting. Dónde se continúa adaptando al conjunto de entrenamiento.\n",
        "\n",
        "Lo que se busca es encontrar el punto dentro del parámetro de profundidad dónde se deja de ajustar a las características de los datos y empieza a memorizarlos.\n",
        "\n",
        "*¿Cómo?*\n",
        "\n",
        "Nuestra propuesta de solución es hacer una gráfica de R2 de prueba y R2 de entrenamiento en comparación al parámetro de max_depth. El objetivo es buscar el punto dónde el R2 de prueba empiece a \"aplanarse\", similar al codo. Además, podemos validar la efectividad de nuestro método planteado al verificar que el R2 de entrenamiento siga aumentando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "AGO6G-I6Ev-P",
        "outputId": "b3763730-c190-49e2-f044-b23ce4b5cac1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "depths = range(1, 21)\n",
        "\n",
        "train_r2 = []\n",
        "test_r2 = []\n",
        "\n",
        "for depth in depths:\n",
        "    regressor = DecisionTreeRegressor(max_depth=depth, random_state=42)\n",
        "    regressor.fit(X_train, Y_train)\n",
        "\n",
        "    Y_train_pred = regressor.predict(X_train)\n",
        "    train_r2.append(r2_score(Y_train, Y_train_pred))\n",
        "\n",
        "    Y_test_pred = regressor.predict(X_test)\n",
        "    test_r2.append(r2_score(Y_test, Y_test_pred))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(depths, train_r2, marker='o', linestyle='--', label='Training R²')\n",
        "plt.plot(depths, test_r2, marker='o', linestyle='--', label='Test R²')\n",
        "plt.xlabel('Tree Depth')\n",
        "plt.ylabel('R²')\n",
        "plt.title('Training and Test R² vs Tree Depth')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "selected_point = 7\n",
        "plt.axvline(x=selected_point, color='red', linestyle='--', label=f'Punto de Interés (Depth = {selected_point})')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RoNs-L9JJ4L"
      },
      "source": [
        "*Análisis de la Gráfica*\n",
        "\n",
        "La gráfica generada es bastante interesante, podemos observar algunos de los siguientes puntos clave:\n",
        "\n",
        "- Como se predijo, la curva de Training R2 se va aplanando acercándose cada vez más a 1.\n",
        "\n",
        "- La curva de R2 de entrenamiento parece seguir un trend similar, sin embargo, en contra de las predicciones en lugar de \"aplanarse\" empieza a tener un comportamiento errático.\n",
        "\n",
        "*¿Por qué?*\n",
        "\n",
        "Basados en el análisis realizado anteriormente, sabemos que un mayor ajuste a los datos de entrenamiento puede tener un impacto tanto positivo cómo negativo. Podemos intuir que luego de este punto, el modelo empieza a sobre-ajustar al conjunto de prueba. Luego, la oscilación del modelo puede explicarse cómo un indicador de qué tantas características \"pegaron\" a los datos de entrenamiento que por \"casualidad\" fueron seleccionadas en alguna profundidad. Cuándo se empieza a acercar a 1 el R2 de entrenamiento, esto nos indica que únicamente se están dividiendo de manera diferente (basado en diferentes características) los datos y realmente el ajuste con el set de prueba no es un indicador real de la calidad del modelo.\n",
        "\n",
        "*Solución*\n",
        "\n",
        "Decidimos utilizar un R2 \"cross-validated\" para evitar ligeramente la influencia de \"casualidades\" entre ambos datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "37mYhqPDI6Ja",
        "outputId": "726cd817-0c7f-48ca-915c-c1ee22a7cb2a"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_scores = []\n",
        "for depth in depths:\n",
        "    regressor = DecisionTreeRegressor(max_depth=depth, random_state=42)\n",
        "    scores = cross_val_score(regressor, X_train, Y_train, cv=5, scoring='r2')\n",
        "    cv_scores.append(np.mean(scores))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(depths, cv_scores, marker='o', linestyle='--', label='Cross-Validated R²')\n",
        "plt.xlabel('Tree Depth')\n",
        "plt.ylabel('Cross-Validated R²')\n",
        "plt.title('Cross-Validated R² vs Tree Depth')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ialPm3HXLnyC"
      },
      "source": [
        "*Análisis de la Gráfica*\n",
        "\n",
        "En esta gráfica podemos observar que las oscilaciones cambian ligeramente en comparación a la anterior. Esto nos indica que nuestra predicción fue correcta, las oscilaciones simplemente eran causadas por la diferencia en importancia de características en cada  modelo.\n",
        "\n",
        "*Conclusión*\n",
        "\n",
        "Debido al comportamiento errático del rendimiento del modelo cuándo las predicciones del conjunto de prueba comienzan a ser perfectas, decidimos buscar minimizar el parámetro de depth para nuestro modelo. Además, buscamos el punto dónde encontremos un mayor valor de R2 con las predicciones del modelo del conjunto de prueba. Por eso, seleccionamos cómo número \"óptimo\" max_depth = 7.\n",
        "\n",
        "- Se encuentra antes del comportamiento errático\n",
        "- Su valor de R2 es similar en el calculado con los conjuntos y cross-validated\n",
        "- Se maximiza el performance del modelo en comparación a puntos anteriores "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVU-3-ojs2Nu"
      },
      "source": [
        "## Árbol de Regresión (Max Depth = 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entrenamiento del Modelo y Predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = train_set_strat.drop(columns=['SalePrice'])\n",
        "Y_train = train_set_strat['SalePrice']\n",
        "\n",
        "X_test = test_set_strat.drop(columns=['SalePrice'])\n",
        "Y_test = test_set_strat['SalePrice']\n",
        "\n",
        "regressor = DecisionTreeRegressor(random_state = 42, max_depth = 7)\n",
        "\n",
        "regressor.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = regressor.predict(X_test)\n",
        "Y_train_pred = regressor.predict(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rendimiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "mae = mean_absolute_error(Y_test, Y_pred)\n",
        "r2 = r2_score(Y_test, Y_pred)\n",
        "\n",
        "print(\"Test\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared (R²): {r2}\")\n",
        "\n",
        "mse = mean_squared_error(Y_train, Y_train_pred)\n",
        "mae = mean_absolute_error(Y_train, Y_train_pred)\n",
        "r2 = r2_score(Y_train, Y_train_pred)\n",
        "\n",
        "print(\"Train\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared (R²): {r2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gráficas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(Y_test, Y_pred, alpha=0.5)\n",
        "plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', linestyle='--')  # Diagonal line\n",
        "plt.xlabel(\"Valores Reales\")\n",
        "plt.ylabel(\"Predicciones\")\n",
        "plt.title(\"Valores Reales vs Predicciones\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "residuals = Y_test - Y_pred\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(Y_pred, residuals, alpha=0.5)\n",
        "plt.axhline(y=0, color='red', linestyle='--')  # Horizontal line at 0\n",
        "plt.xlabel(\"Predicted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual Plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN3wMfWZ1JTR"
      },
      "source": [
        "## Comparación con Regresión Lineal (5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmlieqFm1RrQ"
      },
      "source": [
        "## Creación Variable de Respuesta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH8qE-2J1gOb"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QyxQI5m1lXe"
      },
      "source": [
        "## Análisis de Eficiencia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzRInSpN1rmo"
      },
      "source": [
        "## Validación Cruzada"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Lywcs0mkQfPd",
        "i63e2o3sX_gI",
        "OmNBGHFkP3NU",
        "IbvD7WzqQfPf",
        "JrEMDfkTrcb3",
        "dJTGnPbHsPk2",
        "LISzHx7CcYEc",
        "1E_cnfo4ckcw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
